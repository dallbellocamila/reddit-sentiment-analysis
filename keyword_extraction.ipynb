{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8842930-7a79-4779-bbb0-2026a5f7abc9",
   "metadata": {},
   "source": [
    "# Extracting Keywords Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d16cdf35-d69f-4bb3-b9af-c2a282aabca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99a94e17-2f7d-404b-9ec9-85dea69fa47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for extracting news data using mediastack api. Data has already been extracted and is saved in the newsarticle.json file\n",
    "# Thus, code is commented out\n",
    "\n",
    "# import http.client, urllib.parse, json\n",
    "\n",
    "# conn = http.client.HTTPConnection('api.mediastack.com')\n",
    "\n",
    "# for i in range(0, 6):\n",
    "#     params = urllib.parse.urlencode({\n",
    "#         'access_key': '38f726aef9cabcd89940e27f93c99e3f',\n",
    "#         'categories': 'politics',\n",
    "#         'countries': 'us',\n",
    "#         'sort': 'published_desc',\n",
    "#         'limit': 100,\n",
    "#         'offset': i*100,\n",
    "#         # 'keywords': 'election',\n",
    "#         'date': '2024-10-15,2024-11-26'\n",
    "#     })\n",
    "\n",
    "#     conn.request('GET', '/v1/news?{}'.format(params))\n",
    "    \n",
    "#     res = conn.getresponse()\n",
    "#     data = res.read().decode('utf-8')\n",
    "#     news_data += list(json.loads(data)[\"data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c35d4bfb-9955-4308-b3c0-4c1f1a300763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282\n"
     ]
    }
   ],
   "source": [
    "def read_file(file_name):\n",
    "    with open(file_name, \"r\") as json_file:\n",
    "        data = json.load(json_file)\n",
    "    return data\n",
    "\n",
    "\n",
    "def write_file(data, file_name):\n",
    "    with open(file_name, \"w\") as json_file:\n",
    "        json.dump(data, json_file, indent=4)  # `indent=4` makes it pretty-printed\n",
    "\n",
    "news_data = read_file(\"newsarticles.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "f74b173f-8094-4bd6-bd23-a437d91f588d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words most related to 'economy':\n",
      "['prices', 'inflation', 'triggering', 'stock', 'scores', 'expensive', 'felt', 'rates', 'respondents', 'professional', 'economic', 'stamps', 'repercussions', 'roxanne', 'afloat', 'aquaculture', 'priced', 'manageable', 'succumbing', 'necessities']\n",
      "Words most related to 'democracy':\n",
      "['siphoned', 'mudde', 'legalized', 'hence', 'capitalism', 'rectify', 'columns', 'newest', 'reich', 'acquisitions', 'robertreich', 'stalled', 'nausea', 'misallocation', 'inbox', 'rigs', 'cas', 'eldercare', 'summoned', 'corporations']\n",
      "Words most related to 'security':\n",
      "['social', 'shortfall', 'finances', 'insolvency', '2031', 'footing', 'mismanage', 'proposing', 'waving', 'trustees', 'insolvent', 'modernize', 'holland', 'ss', '2033', 'breck', 'dumas', 'angrily', 'buckle', 'oasi']\n",
      "Words most related to 'immigration':\n",
      "['immigrants', 'policies', 'border', 'forgiveness', 'country', 'about', 'sues', 'migrants', 'illegally', 'wanted', 'harris', 'illegal', 'said', 'did', 'from', 'trump', 'on', 'mass', 'for', 'pressed']\n",
      "Words most related to 'education':\n",
      "['pearson', 'indoctrination', 'ferial', 'flopped', 'classrooms', 'oriented', 'devos', '529', 'greenlight', 'partially', 'betsy', 'futureed', 'subsidize', 'absenteeism', 'sparsely', 'charters', 'schreiner', 'petrilli', 'fordham', 'sidelined']\n",
      "Words most related to 'healthcare':\n",
      "['creators', 'schar', '1tn', 'outpolls', 'concepts', 'uninsured', 'blowtorch', 'goer', 'obamacare', 'medicaid', 'affordable', 'replacing', 'boot', 'sections', 'ingrained', 'entrepreneurs', 'subsidies', 'incorporated', 'takers', 'empower']\n",
      "Words most related to 'abortion':\n",
      "['roe', 'bans', 'ban', 'wade', 'abortions', 'life', 'incest', 'exceptions', 'procedure', 'restrictions', 'obtain', 'care', 'pregnancy', 'guaranteeing', 'rape', 'unelected', 'votingtim', 'moderates', 'callous', 'allredrepublicans']\n"
     ]
    }
   ],
   "source": [
    "# find cosine similarity of relevant categories to the election\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Sample documents\n",
    "documents = news_data\n",
    "\n",
    "# Create a count matrix\n",
    "vectorizer = CountVectorizer()\n",
    "count_matrix = vectorizer.fit_transform(documents).toarray()\n",
    "\n",
    "# Create a word-to-index mapping\n",
    "vocab = vectorizer.get_feature_names_out()\n",
    "word_to_index = {word: idx for idx, word in enumerate(vocab)}\n",
    "\n",
    "# Find co-occurrence vectors for a target word\n",
    "keywords = {\"economy\": [], \"democracy\": [], \"security\": [], \"immigration\": [], \"education\": [], \"healthcare\": [], \"abortion\": []}\n",
    "for keyword in keywords:\n",
    "    if keyword in word_to_index:\n",
    "        target_idx = word_to_index[keyword]\n",
    "        target_vector = count_matrix[:, target_idx]\n",
    "    \n",
    "        # Calculate cosine similarity with all other words\n",
    "        similarities = cosine_similarity(target_vector.reshape(1, -1), count_matrix.T).flatten()\n",
    "    \n",
    "        # Get top related words\n",
    "        related_indices = similarities.argsort()[::-1][1:21]\n",
    "        print(f\"Words most related to '{keyword}':\")\n",
    "        for idx in related_indices:\n",
    "            keywords[keyword].append(vocab[idx])\n",
    "        print(keywords[keyword])\n",
    "    else:\n",
    "        print(f\"'{target_word}' not found in the vocabulary.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "da3c22e8-6068-491c-b18e-983c9de612b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to file\n",
    "write_file(keywords, \"keywords.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa51ca2-51a1-4477-aa30-2e1f4b74f52d",
   "metadata": {},
   "source": [
    "# End of Script"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
